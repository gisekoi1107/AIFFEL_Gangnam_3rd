{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56dbd71",
   "metadata": {},
   "source": [
    "# 프로젝트: 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb713c",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cef32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import re                  \n",
    "import numpy as np         \n",
    "import tensorflow as tf \n",
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95251423",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599801c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n",
      "You saw her bathing on the roof\n",
      "Her beauty and the moonlight overthrew her\n",
      "She tied you\n",
      "To a kitchen chair\n",
      "She broke your throne, and she cut your hair\n",
      "And from your lips she drew the Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah You say I took the name in vain\n",
      "I don't even know the name\n",
      "But if I did, well really, what's it to you?\n",
      "There's a blaze of light\n",
      "In every word\n",
      "It doesn't matter which you heard\n",
      "The holy or the broken Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah I did my best, it wasn't much\n",
      "I couldn't feel, so I tried to touch\n",
      "I've told the truth, I didn't come to fool you\n",
      "And even though\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   \n",
    "    if idx > 30: break   \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7e2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)       \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)              \n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  \n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      \n",
    "    \n",
    "    if \"verse\" in sentence:\n",
    "        sentence = sentence.replace(\"verse\", \"\")\n",
    "    if \"chorus\" in sentence:\n",
    "        sentence = sentence.replace(\"chorus\", \"\")\n",
    "    \n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4613420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175950\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if len(sentence) == 1: continue    \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "corpus.remove('<start>  <end>')         \n",
    "\n",
    "corpus[:30]\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d57fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/lib/function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152501\n",
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   92   12 ...    0    0    0]\n",
      " [   2   78  921 ...    0    0    0]\n",
      " ...\n",
      " [   5   22    9 ...   10 1013    3]\n",
      " [  37   15 9056 ...  876  642    3]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f9a14c61550>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000,  \n",
    "        filters=' ',    \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)  \n",
    "   \n",
    "    for num in tensor:\n",
    "        if len(num) >= 29:\n",
    "            tensor = np.delete(tensor, num)\n",
    "            \n",
    "    print(len(tensor))\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=15)  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "    \n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be546f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c12b480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    5   91  296   64   57    9  968 6044    3    0    0    0]\n",
      "[  50    5   91  296   64   57    9  968 6044    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4459f7",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52914e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707dc350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (122000, 14)\n",
      "Target Train: (122000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b7a7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)         \n",
    "BATCH_SIZE = 256                     \n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64a8f8",
   "metadata": {},
   "source": [
    "## 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211a0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.drop  = tf.keras.layers.Dropout(0.5)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9798873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 15001), dtype=float32, numpy=\n",
       "array([[[ 9.0868147e-05,  1.9450799e-04,  1.6385816e-04, ...,\n",
       "         -2.8930910e-04, -4.0756033e-05,  4.3191649e-05],\n",
       "        [-1.6667617e-04,  4.2466997e-04,  1.3034903e-04, ...,\n",
       "         -3.7367956e-04, -4.3836848e-05,  3.6494841e-06],\n",
       "        [-3.0145916e-04,  5.0106266e-04, -2.1126274e-05, ...,\n",
       "         -3.1820615e-04, -1.8106023e-04, -1.3844798e-04],\n",
       "        ...,\n",
       "        [ 1.2750608e-04,  1.0015062e-03,  2.5199790e-04, ...,\n",
       "         -1.8810046e-04, -5.1423500e-04, -7.7926525e-04],\n",
       "        [ 3.1586282e-04,  1.0989244e-03,  2.1397055e-04, ...,\n",
       "         -4.9886945e-05, -5.3765363e-04, -7.4894220e-04],\n",
       "        [ 5.2299100e-04,  1.1794909e-03,  1.9736223e-04, ...,\n",
       "          3.5670440e-05, -5.0396571e-04, -7.2890020e-04]],\n",
       "\n",
       "       [[-9.1361301e-07, -1.2405004e-04, -7.4469426e-05, ...,\n",
       "         -6.5202017e-05,  2.3403889e-04,  3.2277475e-04],\n",
       "        [ 7.5359843e-05, -5.3671194e-04, -2.3804678e-04, ...,\n",
       "         -5.6604167e-05,  3.3618044e-04,  4.1641385e-04],\n",
       "        [ 9.9067373e-05, -8.8300672e-04, -3.2921208e-04, ...,\n",
       "         -2.5164467e-05,  4.9395551e-04,  4.2211910e-04],\n",
       "        ...,\n",
       "        [ 1.1151478e-03, -8.1812538e-04, -3.9118063e-04, ...,\n",
       "         -3.7784546e-04,  3.4465193e-05, -6.7207188e-04],\n",
       "        [ 1.0345074e-03, -5.0987257e-04, -3.3364614e-04, ...,\n",
       "         -4.4640576e-04, -1.5924054e-06, -6.5871538e-04],\n",
       "        [ 1.0869638e-03, -4.9260672e-04, -2.6619283e-04, ...,\n",
       "         -2.2208368e-04,  7.0280017e-05, -6.5467757e-04]],\n",
       "\n",
       "       [[-9.1361301e-07, -1.2405004e-04, -7.4469426e-05, ...,\n",
       "         -6.5202017e-05,  2.3403889e-04,  3.2277475e-04],\n",
       "        [ 3.9806808e-05, -4.2689263e-04, -3.1419189e-05, ...,\n",
       "          1.4089818e-04,  2.5204438e-04,  5.9253961e-04],\n",
       "        [ 7.2732328e-05, -5.8209343e-04, -9.0684676e-05, ...,\n",
       "          3.3335952e-04,  3.3391910e-04,  7.0962851e-04],\n",
       "        ...,\n",
       "        [ 2.5173550e-04, -1.2138009e-03,  2.9916450e-04, ...,\n",
       "          1.2333007e-03,  1.4898920e-04,  5.7365127e-05],\n",
       "        [ 4.3068652e-04, -1.2507414e-03,  2.8003822e-04, ...,\n",
       "          1.6822413e-03,  2.8509839e-04, -1.4615202e-04],\n",
       "        [ 6.1356102e-04, -1.2587294e-03,  2.3674312e-04, ...,\n",
       "          2.1191351e-03,  4.2213275e-04, -3.3371660e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-9.1361301e-07, -1.2405004e-04, -7.4469426e-05, ...,\n",
       "         -6.5202017e-05,  2.3403889e-04,  3.2277475e-04],\n",
       "        [ 1.0728002e-04,  4.1411120e-05, -1.2040123e-04, ...,\n",
       "         -2.0498960e-04,  3.2832741e-04,  4.8951095e-04],\n",
       "        [ 2.0381654e-04, -2.8536948e-05, -4.8955530e-04, ...,\n",
       "          4.9837108e-05,  4.7008862e-04,  6.9268065e-04],\n",
       "        ...,\n",
       "        [ 8.3812140e-04, -2.0270667e-05,  2.5027417e-04, ...,\n",
       "          4.2391004e-04,  7.0620689e-04, -4.8854930e-04],\n",
       "        [ 8.8773901e-04, -9.4048410e-05,  3.0636552e-04, ...,\n",
       "          6.0027378e-04,  6.6964299e-04, -5.2748551e-04],\n",
       "        [ 9.9022640e-04, -2.6030009e-04,  2.9332979e-04, ...,\n",
       "          9.0125808e-04,  7.0157723e-04, -5.9011258e-04]],\n",
       "\n",
       "       [[-9.1361301e-07, -1.2405004e-04, -7.4469426e-05, ...,\n",
       "         -6.5202017e-05,  2.3403889e-04,  3.2277475e-04],\n",
       "        [-1.7085727e-04, -3.2080608e-04, -8.2560349e-05, ...,\n",
       "          1.6971618e-04,  2.2123966e-04,  3.6243952e-04],\n",
       "        [-1.7225798e-04, -4.0785127e-04, -1.8806432e-04, ...,\n",
       "          2.0600163e-04,  3.2844974e-04,  9.0962189e-05],\n",
       "        ...,\n",
       "        [-3.9001850e-05,  8.5224578e-04,  2.1766726e-04, ...,\n",
       "          8.5212395e-04,  5.1669747e-04, -8.6734223e-04],\n",
       "        [ 1.1351598e-04,  5.1142822e-04,  3.5320356e-04, ...,\n",
       "          1.2031881e-03,  5.4941751e-04, -8.7051850e-04],\n",
       "        [ 3.0654733e-04,  1.6062972e-04,  4.0913626e-04, ...,\n",
       "          1.6117318e-03,  6.3664513e-04, -8.7322586e-04]],\n",
       "\n",
       "       [[ 1.5176587e-04, -2.0193987e-04, -9.5071926e-05, ...,\n",
       "         -9.4607218e-05,  1.0736206e-04, -1.0102436e-04],\n",
       "        [ 9.2080081e-05, -3.7013541e-04, -2.6244263e-04, ...,\n",
       "         -2.5902031e-04,  2.8588646e-04, -1.7541429e-04],\n",
       "        [ 1.6846029e-04, -6.2537845e-04, -2.4290261e-04, ...,\n",
       "         -2.5064734e-04,  2.7165326e-04, -3.8785921e-04],\n",
       "        ...,\n",
       "        [ 4.1291813e-04,  3.2578627e-04,  2.0393163e-04, ...,\n",
       "          3.7130949e-04,  1.7215083e-04, -7.2627992e-04],\n",
       "        [ 4.6350577e-04,  1.0391901e-04,  3.1798382e-04, ...,\n",
       "          3.0424015e-04,  1.8472904e-04, -7.8241160e-04],\n",
       "        [ 4.7122347e-04, -1.3094122e-04,  2.0805375e-04, ...,\n",
       "          2.9419252e-04,  2.2373487e-04, -6.4707024e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad3e620e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3840256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  15376025  \n",
      "=================================================================\n",
      "Total params: 32,855,961\n",
      "Trainable params: 32,855,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d52f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "595/595 [==============================] - 118s 191ms/step - loss: 3.7451\n",
      "Epoch 2/30\n",
      "595/595 [==============================] - 115s 193ms/step - loss: 3.2495\n",
      "Epoch 3/30\n",
      "595/595 [==============================] - 115s 193ms/step - loss: 3.0728\n",
      "Epoch 4/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.9502\n",
      "Epoch 5/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.8446\n",
      "Epoch 6/30\n",
      "595/595 [==============================] - 115s 193ms/step - loss: 2.7530\n",
      "Epoch 7/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 2.6668\n",
      "Epoch 8/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 2.5844\n",
      "Epoch 9/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.5062\n",
      "Epoch 10/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.4297\n",
      "Epoch 11/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.3563\n",
      "Epoch 12/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 2.2855\n",
      "Epoch 13/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 2.2163\n",
      "Epoch 14/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 2.1491\n",
      "Epoch 15/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 2.0849\n",
      "Epoch 16/30\n",
      "595/595 [==============================] - 116s 195ms/step - loss: 2.0236\n",
      "Epoch 17/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 1.9649\n",
      "Epoch 18/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 1.9084\n",
      "Epoch 19/30\n",
      "595/595 [==============================] - 116s 195ms/step - loss: 1.8549\n",
      "Epoch 20/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.8055\n",
      "Epoch 21/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.7583\n",
      "Epoch 22/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.7144\n",
      "Epoch 23/30\n",
      "595/595 [==============================] - 116s 195ms/step - loss: 1.6732\n",
      "Epoch 24/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.6317\n",
      "Epoch 25/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.5943\n",
      "Epoch 26/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 1.5604\n",
      "Epoch 27/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.5281\n",
      "Epoch 28/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.4960\n",
      "Epoch 29/30\n",
      "595/595 [==============================] - 116s 194ms/step - loss: 1.4678\n",
      "Epoch 30/30\n",
      "595/595 [==============================] - 115s 194ms/step - loss: 1.4401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99982c6250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b659c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954/954 - 13s - loss: 1.1756\n",
      "1.1755937337875366\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(enc_val,  dec_val, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d74a88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        predict = model(test_tensor)  \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   \n",
    "        \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "     \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa4d490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a881789a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> do you remember the time <end> '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> do you\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09a80d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> only the <unk> can disclose <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec0ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> why you wanna get with me <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> why\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e53eff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> who s that casting devious stares in my direction ? <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> who\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a928b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
